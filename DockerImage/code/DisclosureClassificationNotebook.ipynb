{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a14b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sqlite3\n",
    "import sys\n",
    "output_dir = \"../../ext/combined_tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c63961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "policyCsv = os.path.join(output_dir, \"Policy.csv\")\n",
    "policyDf = pd.read_csv(policyCsv, \n",
    "\t\t\tusecols=[\"policyId\",\"entity\",\"action\",\"data\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"policyId\" : int, \"entity\" : str,\"action\" : str,\"data\" : str\n",
    "\t\t\t},\n",
    "\t\t\tskip_blank_lines=True)\n",
    "policyDf.fillna({\n",
    "\t\t\t\t\"policyId\" : -1,\"entity\" : '',\"action\" : '',\"data\" : ''\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "policySentencesCsv = os.path.join(output_dir, \"PolicySentences.csv\")\n",
    "policySentencesDf = pd.read_csv(policySentencesCsv,\n",
    "\t\t\tusecols=[\"id\", \"sentenceId\", \"policyId\", \"appId\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"id\" : int, \"sentenceId\" : str, \"policyId\" : int, \"appId\" : str\n",
    "\t\t\t},\n",
    "\t\t\tskip_blank_lines=True)\n",
    "policySentencesDf.fillna({\n",
    "\t\t\t\t\"id\" : -1, \"sentenceId\" : '', \"policyId\" : -1, \"appId\" : ''\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "policySentencesDf[\"shouldIgnore\"] = False\n",
    "\n",
    "dataflowCsv = os.path.join(output_dir, \"DataFlows.csv\")\n",
    "dataflowDf = pd.read_csv(dataflowCsv,\n",
    "\t\t\tusecols=[\"flowId\", \"flowEntity\", \"flowData\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"flowId\" : int, \"flowEntity\" : str, \"flowData\" : str\n",
    "\t\t\t},\n",
    "\t\t\tskip_blank_lines=True)\n",
    "dataflowDf.fillna({\n",
    "\t\t\t\t\"flowId\" : -1, \"flowEntity\" : '', \"flowData\" : ''\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "appDataflowCsv = os.path.join(output_dir, \"AppDataFlows.csv\")\n",
    "appDataflowDf = pd.read_csv(appDataflowCsv,\n",
    "\t\t\tusecols=[\"appFlowId\", \"flowId\", \"appId\", \"rawEntity\", \"rawData\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"appFlowId\" : int, \"flowId\" : int, \"appId\" : str, \"rawEntity\" : str, \"rawData\" : str\n",
    "\t\t\t},\n",
    "\t\t\tskip_blank_lines=True)\n",
    "appDataflowDf.fillna({\n",
    "\t\t\t\t\"appFlowId\" : -1, \"flowId\" : -1, \"appId\" : '', \"rawEntity\" : '', \"rawData\" : ''\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "consistencyResultCsv = os.path.join(output_dir, \"ConsistencyResult.csv\")\n",
    "conResDf = pd.read_csv(consistencyResultCsv,\n",
    "\t\t\tusecols=[\"consistId\", \"flowId\", \"appId\", \"isConsistent\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"consistId\" : int, \"flowId\" : int, \"appId\" : str, \"isConsistent\" : str\n",
    "\t\t\t},\n",
    "\t\t\tskip_blank_lines=True)\n",
    "conResDf.fillna({\n",
    "\t\t\t\t\"consistId\" : -1, \"flowId\" : -1, \"appId\" : '', \"isConsistent\" : ''\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "contradictionMap = {\n",
    "\t-1 : None, 0  : \"C1\", 1  : \"C2\", 2  : \"N1\", 3  : \"C6\", 4  : \"C3\", 5  : \"C4\", 6  : \"N2\", 7  : \"C7\", 8  : \"N3\", \n",
    "\t9  : \"C5\", 10 : \"N4\", 11 : \"C8\", 12 : \"C9\", 13 : \"C10\", 14 : \"C11\", 15 : \"C12\",\n",
    "}\n",
    "\n",
    "consistencyDataCsv = os.path.join(output_dir, \"ConsistencyData_wo_samesencontr.csv\")\n",
    "conDataDf = pd.read_csv(consistencyDataCsv,\n",
    "\t\t\tusecols=[\"cdid\", \"consistId\", \"policyStatement\", \"contradictingStatement\", \"contradictionNum\"],\n",
    "\t\t\tdtype = {\n",
    "\t\t\t\t\"cdid\" : int, \"consistId\" : int, \"policyStatement\" : int,\n",
    "\t\t\t\t\"contradictingStatement\" : float, \"contradictionNum\" : int,\n",
    "\t\t\t}, \n",
    "\t\t\tskip_blank_lines=True)\n",
    "conDataDf.fillna({\n",
    "\t\t\t\t\"cdid\" : -1, \"consistId\" : -1, \"policyStatement\" : -1,\n",
    "\t\t\t\t\"contradictingStatement\" : -1, \"contradictionNum\" : -1\n",
    "\t\t\t}, inplace = True)\n",
    "\n",
    "conDataDf[\"contradictionNum\"] = conDataDf[\"contradictionNum\"].replace(contradictionMap)\n",
    "conDataDf[[\"contradictingStatement\"]] = conDataDf[[\"contradictingStatement\"]].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#Heuristic to remove broad info mentions...\n",
    "corefCheck = re.compile(r\"\"\"\\b(this|that|these|those|such)\\s((type(s)?|kind(s)|categor(ies|y))\\sof\\s)?(request(ed)?\\s)?(personal|personally(\\s|\\-)identifiable)?(information|data|content|datum|detail(s)?)\\b\"\"\", re.IGNORECASE)\n",
    "\n",
    "totalExclude = 0\n",
    "for index, psid, sentenceText, policyId, appId,_ in policySentencesDf.itertuples():\n",
    "\t_,pEntity,pAction,pData = policyDf.loc[ policyDf[\"policyId\"] == policyId ].values[0]\n",
    "\tif pData == \"information\" and corefCheck.search(sentenceText):\n",
    "\t\tpolicySentencesDf.at[index, \"shouldIgnore\"] = True\n",
    "\t\ttotalExclude += 1\n",
    "#print(\"Excluded \", totalExclude, 'sentences out of', len(policySentencesDf))\n",
    "\n",
    "policySentencesDf.to_csv(\"PolicySentences_w_shouldIgnore.csv\", sep=str(','), encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "psRemovedDf = policySentencesDf.loc[ policySentencesDf[\"shouldIgnore\"] == True ]\n",
    "potImpactConsistIds = set()\n",
    "#Get keys of potential rows impacted...\n",
    "for _,sid, sText, policyId, appId,_ in psRemovedDf.itertuples():\n",
    "\tcrDf = conResDf.loc[ conResDf[\"appId\"] == appId ]\n",
    "\tfor _,consistId, flowId, _, _ in crDf.itertuples():\n",
    "\t\tcdDf = conDataDf.loc[ (conDataDf[\"consistId\"] == consistId) ]\n",
    "\t\tfor _,cdid, _, sPolicyId1, cPolicyId2, contrNum in cdDf.itertuples():\n",
    "\t\t\tif sPolicyId1 == policyId or cPolicyId2 == policyId:\n",
    "\t\t\t\tpotImpactConsistIds.add(consistId)\n",
    "\n",
    "#print(len(potImpactConsistIds))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "for _,consistId, flowId, appId, _ in conResDf.itertuples():\n",
    "\t# Get all policy statements that either justified or did not justify beforehand...\n",
    "\tcdata = conDataDf.loc[ conDataDf[\"consistId\"] == consistId ]\n",
    "\t# Get all the unignored policy statements\n",
    "\tpids = [ a[0] for a in policySentencesDf.loc[ (policySentencesDf[\"appId\"] == appId) & (policySentencesDf[\"shouldIgnore\"] == False) ].groupby(\"policyId\")[\"policyId\"].unique().tolist() ]\n",
    "\n",
    "\tfor index,cdid, _, p1, c1, ct in cdata.itertuples():\n",
    "\t\tif p1 in pids and (c1 in pids or c1 == -1):#Nothing changed...\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tif p1 not in pids and c1 not in pids:# Remove entirely\n",
    "\t\t\tprint(\"Remove1\", c1, p1, appId)\n",
    "\t\t\tconDataDf.drop(index, inplace=True)\n",
    "\t\tif p1 not in pids and c1 in pids:#Remove p1 and move c1 to p1\n",
    "\t\t\tprint(\"Remove2\", p1, appId)\n",
    "\t\t\tconDataDf.at[index, \"policyStatement\"] = conDataDf.at[index, \"contradictingStatement\"]\n",
    "\t\t\tconDataDf.at[index, \"contradictingStatement\"] = -1\n",
    "\t\t\tconDataDf.at[index, \"contradictionNum\"] = contradictionMap[-1]\n",
    "\t\tif p1 in pids and c1 != -1 and c1 not in pids:#Remove c1\n",
    "\t\t\tprint(\"Remove3\", c1, appId)\n",
    "\t\t\tconDataDf.at[index, \"contradictingStatement\"] = -1\n",
    "\t\t\tconDataDf.at[index, \"contradictionNum\"] = contradictionMap[-1]\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "dataOnt = pickle.load(open('../../ext/data/data_ontology.pickle', 'rb'))\n",
    "entOnt = pickle.load(open('../../ext/data/entity_ontology.pickle', 'rb'))\n",
    "\n",
    "def getDistanceBetweenNodes(flowNode, policyNode, ont):\n",
    "\treturn len(nx.shortest_path(ont, source=policyNode, target=flowNode)) - 1\n",
    "\n",
    "def getNormalizedDistanceBetweenNodes(flowNode, policyNode, ontology, root):\n",
    "\tftpDistance = float(getDistanceBetweenNodes(flowNode, policyNode, ontology))\n",
    "\tptrDistance = float(getDistanceBetweenNodes(policyNode, root, ontology))\n",
    "\treturn ftpDistance / (ftpDistance + ptrDistance)\n",
    "\n",
    "def resolvePolicyStatement(pid):\n",
    "\tif pid is None or pid == -1:\n",
    "\t\treturn (None, None, None)\n",
    "\t_,pEntity,pSentiment,pData = policyDf.loc[ policyDf[\"policyId\"] == pid ].values[0]\n",
    "\treturn (pEntity,pSentiment,pData)\n",
    "\n",
    "def writeCsvRow(csvfile, packageName, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, consistencyResult, entityVagueness, entityVaguenessRaw, dataVagueness, dataVaguenessRaw, contradictionNum, contradictoryEntity, contradictoryAction, contradictoryData, contradictionSentences):\n",
    "\tcsvfile.writerow((packageName, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences.encode(\"utf-8\") if policySentences is not None else None, consistencyResult, entityVagueness, entityVaguenessRaw, dataVagueness, dataVaguenessRaw, contradictionNum, contradictoryEntity, contradictoryAction, contradictoryData, contradictionSentences.encode(\"utf-8\") if contradictionSentences is not None else None))\n",
    "\n",
    "def writeCsvHeader(csvfile):\n",
    "\tcsvfile.writerow((\"packageName\", \"flowEntity\", \"flowData\", \"policyEntity\", \"policyAction\", \"policyData\", \"policySentences\", \"consistencyResult\", \"entityVagueness\", \"entityVaguenessRaw\", \"dataVagueness\", \"dataVaguenessRaw\", \"contradictionNum\", \"contradictoryEntity\", \"contradictoryAction\", \"contradictoryData\", \"contradictionSentences\"))\n",
    "\n",
    "def filteredAppend(PF, p1, pEntity, pSentiment, pData, cType, cPol):\n",
    "\tif flowEntity == u\"we\" and pEntity != u'we':\n",
    "\t\treturn#First party should not be \"anyone\"\n",
    "\tif cPol is not None:\n",
    "\t\tc1, cEntity, cSentiment, cData = cPol\n",
    "\t\tif flowEntity == u\"we\" and cEntity != u'we':\n",
    "\t\t\treturn#Again, first party should not be \"anyone\"\n",
    "\tPF.append((p1, pEntity, pSentiment, pData, cType, cPol))\n",
    "\n",
    "def getPolicyStatementTypes(xdata, flowEntity):\n",
    "\tPFP = []#Positive\n",
    "\tPFN = []#Negative\n",
    "\tPN = []#Narrowing\n",
    "\tPC = []#Contradictions\n",
    "\n",
    "\tfor index,_, _, p1, c1,ctype in xdata.itertuples():\n",
    "\t\tpEntity,pSentiment,pData = resolvePolicyStatement(p1)\n",
    "\t\tcEntity,cSentiment,cData = resolvePolicyStatement(c1)\n",
    "\n",
    "\t\tif pSentiment == \"collect\":\n",
    "\t\t\tfilteredAppend(PFP, p1, pEntity, pSentiment, pData, None, None)\n",
    "\t\t\t#PFP.append((p1, pEntity, pSentiment, pData, None, None))\n",
    "\t\telse:\n",
    "\t\t\tfilteredAppend(PFN, p1, pEntity, pSentiment, pData, None, None)\n",
    "\t\t\t#PFN.append((p1, pEntity, pSentiment, pData, None, None))\n",
    "\n",
    "\t\tif cSentiment is not None and cSentiment == \"collect\":\n",
    "\t\t\tfilteredAppend(PFP, c1, cEntity, cSentiment, cData, None, None)\n",
    "\t\t\t#PFP.append((c1, cEntity, cSentiment, cData, None, None))\n",
    "\t\telif cSentiment is not None:\n",
    "\t\t\tfilteredAppend(PFN, c1, cEntity, cSentiment, cData, None, None)\n",
    "\t\t\t#PFN.append((c1, cEntity, cSentiment, cData, None, None))\n",
    "\n",
    "\t\tif ctype is not None:\n",
    "\t\t\tif ctype.startswith(\"C\"):\n",
    "\t\t\t\tfilteredAppend(PC, p1, pEntity, pSentiment, pData, ctype, (c1, cEntity, cSentiment, cData))\n",
    "\t\t\t\tfilteredAppend(PC, c1, cEntity, cSentiment, cData, ctype, (p1, pEntity, pSentiment, pData))\n",
    "#\t\t\t\tPC.append((p1, pEntity, pSentiment, pData, ctype, (c1, cEntity, cSentiment, cData)))\n",
    "#\t\t\t\tPC.append((c1, cEntity, cSentiment, cData, ctype, (p1, pEntity, pSentiment, pData)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tfilteredAppend(PN, p1, pEntity, pSentiment, pData, ctype, (c1, cEntity, cSentiment, cData))\n",
    "\t\t\t\tfilteredAppend(PN, c1, cEntity, cSentiment, cData, ctype, (p1, pEntity, pSentiment, pData))\n",
    "\t\t\t\t#PN.append((p1, pEntity, pSentiment, pData, ctype, (c1, cEntity, cSentiment, cData)))\n",
    "\t\t\t\t#PN.append((c1, cEntity, cSentiment, cData, ctype, (p1, pEntity, pSentiment, pData)))\n",
    "\treturn (PFP, PFN, PN, PC)\n",
    "\n",
    "def isDirectMatch(flowEntity, flowData, policyEntity, policyData):\n",
    "\treturn flowEntity == policyEntity and flowData == policyData\n",
    "\n",
    "def resolveNearestPolicy(flowEntity, flowData, policies):\n",
    "\trankedList = []\n",
    "\tfor pid,e,c,d,ctype,contr in policies:\n",
    "\t\tif isDirectMatch(flowEntity, flowData, e, d):\n",
    "\t\t\treturn (0, 0, pid, e, c, d, ctype, contr)\n",
    "\t\tentityDistance = getDistanceBetweenNodes(flowEntity, e, entOnt)\n",
    "\t\tdataDistance = getDistanceBetweenNodes(flowData, d, dataOnt)\n",
    "\t\trankedList.append((entityDistance, dataDistance, pid, e, c, d, ctype, contr))\n",
    "\trankedList = sorted(rankedList)\n",
    "\treturn rankedList[0]\n",
    "\n",
    "def convertToUnicode(val):\n",
    "\treturn val\n",
    "#\tif type(val) == str:\n",
    "#\t\treturn unicode(val, \"utf-8\")\n",
    "#\treturn val\n",
    "\n",
    "def getSentences(policyId, appId):\n",
    "\tsentences = []\n",
    "\tres = policySentencesDf.loc[(policySentencesDf[\"appId\"] == appId) & (policySentencesDf[\"policyId\"] == policyId) & (policySentencesDf[\"shouldIgnore\"] == False)]\n",
    "\tfor _, _, sentenceText, _, _,_ in res.itertuples():\n",
    "\t\tsentences.append(convertToUnicode(sentenceText))\n",
    "\treturn u\"||\".join(sentences)\n",
    "\n",
    "\n",
    "outputfile = open('../../ext/policheck_results.csv', 'w')\n",
    "csvfile = csv.writer(outputfile, delimiter=str(','))\n",
    "\n",
    "writeCsvHeader(csvfile)\n",
    "\n",
    "finImpactCoref = set()\n",
    "\n",
    "for _,consistId, flowId, appId, _ in conResDf.itertuples():\n",
    "\t_,flowEntity,flowData = dataflowDf.loc[ dataflowDf[\"flowId\"] == flowId ].values[0]\n",
    "\tcdata = conDataDf.loc[ conDataDf[\"consistId\"] == consistId ]\n",
    "\tPFp, PFn, PN, PC = getPolicyStatementTypes(cdata, flowEntity)\n",
    "\n",
    "\t#If PN == 0 and PC == 0 and PFp == PFn\n",
    "\tif len(PN) == 0 and len(PC) == 0 and len(PFp) > 0 and len(PFn) > 0: #We had a same sentence contradiction that we removed, let's find the closest match and wipe the rest...\n",
    "\t\t_, _, pid, policyEntity, policyAction, policyData,_,_ = resolveNearestPolicy(flowEntity, flowData, PFn + PFp)\n",
    "\t\tif policyAction == 'collect':\n",
    "\t\t\tPFn = []\n",
    "\t\telse:\n",
    "\t\t\tPFp = []\n",
    "\n",
    "\tif len(PFp) == 0 and len(PFn) == 0:\n",
    "\t\tif consistId in potImpactConsistIds:\n",
    "\t\t\tfinImpactCoref.add(consistId)\n",
    "\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, None, None, None, None, \"omitted\", None, None, None, None, None, None, None, None, None)\n",
    "\t\tpass\n",
    "\telif (len(PFp) == 0 and len(PFn) > 0):# PN and PC are empty in this case...\n",
    "\t\t# Incorrect\n",
    "\t\t_, _, pid, policyEntity, policyAction, policyData,_,_ = resolveNearestPolicy(flowEntity, flowData, PFn)\n",
    "\t\tpolicySentences = getSentences(pid, appId)\n",
    "\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, \"incorrect\", None, None, None, None, None, None, None, None, None)\n",
    "\telif len(PFp) > 0 and len(PFn) == 0:\n",
    "\t\tentDist, dataDist, pid, policyEntity, policyAction, policyData, _, _ = resolveNearestPolicy(flowEntity, flowData, PFp)\n",
    "\t\tif entDist == 0 and dataDist == 0:\n",
    "\t\t\tpolicySentences = getSentences(pid, appId)\n",
    "\t\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, \"clear\", 0.0, 0.0, 0.0, 0.0, None, None, None, None, None)\n",
    "\t\telse:\n",
    "\t\t\tpolicySentences = getSentences(pid, appId)\n",
    "\t\t\tentityVagueness = getNormalizedDistanceBetweenNodes(flowEntity, policyEntity, entOnt, \"anyone\") if policyEntity != 'we' else 0.0\n",
    "\t\t\tdataVagueness = getNormalizedDistanceBetweenNodes(flowData, policyData, dataOnt, \"information\")\n",
    "\t\t\tentityVaguenessRaw = getDistanceBetweenNodes(flowEntity, policyEntity, entOnt) if policyEntity != 'we' else 0.0\n",
    "\t\t\tdataVaguenessRaw = getDistanceBetweenNodes(flowData, policyData, dataOnt)\n",
    "\t\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, \"vague\", entityVagueness, entityVaguenessRaw, dataVagueness, dataVaguenessRaw, None, None, None, None, None)\n",
    "\telif len(PC) > 0:\n",
    "\t\t# Ambiguous\n",
    "\t\t_, _, pid, policyEntity, policyAction, policyData, ctype, contr = resolveNearestPolicy(flowEntity, flowData, PC)\n",
    "\t\tcontrPid,contradictoryEntity,contradictoryAction,contradictoryData = contr\n",
    "\t\tpolicySentences = getSentences(pid, appId)\n",
    "\t\tcontradictionSentences = getSentences(contrPid, appId)\n",
    "\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, \"ambiguous\", None, None, None, None, ctype, contradictoryEntity, contradictoryAction, contradictoryData, contradictionSentences)\n",
    "\telif len(PN) > 0 and len(PC) <= 0:\n",
    "\t\t_, _, pid, policyEntity, policyAction, policyData, ctype, contr = resolveNearestPolicy(flowEntity, flowData, PN)\n",
    "\t\tcontrPid,contradictoryEntity,contradictoryAction,contradictoryData = contr\n",
    "\t\tpolicySentences = getSentences(pid, appId)\n",
    "\t\tcontradictionSentences = getSentences(contrPid, appId)\n",
    "\t\twriteCsvRow(csvfile, appId, flowEntity, flowData, policyEntity, policyAction, policyData, policySentences, \"incorrect\", None, None, None, None, ctype, contradictoryEntity, contradictoryAction, contradictoryData, contradictionSentences)\n",
    "\t\t#Incorrect\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tprint(\"Warning: We did not classify a flow...\", appId, len(PFp), len(PFn), len(PN), len(PC))\n",
    "outputfile.close()\n",
    "\n",
    "\n",
    "#print(\"Number Of rows impacted by coreference resolution: {}\".format(len(finImpactCoref)))\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-policheckbert",
   "language": "python",
   "name": "venv-policheckbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
