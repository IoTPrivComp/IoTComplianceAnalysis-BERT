{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aefcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "from lxml import etree\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7d6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAnnotations(filename='../../ext/data/synonyms.xml'):\n",
    "\tdef getTerm(node):\n",
    "\t\treturn node.get(u'term')\n",
    "\n",
    "\tdef loadAnnotInternal(node, ignoreList, synAnnot):\n",
    "\t\tif node.tag == u'node':\n",
    "\t\t\tterm = getTerm(node)\n",
    "\t\t\tif term not in synAnnot:\n",
    "\t\t\t\tsynAnnot[term] = term\n",
    "\t\t\tfor child in node:\n",
    "\t\t\t\tif child.tag == u'synonym':\n",
    "\t\t\t\t\tchildTerm = getTerm(child)\n",
    "\t\t\t\t\tif childTerm not in synAnnot:\n",
    "\t\t\t\t\t\tsynAnnot[childTerm] = term\n",
    "\t\t\t\telif child.tag in [u'node', u'ignore']:\n",
    "\t\t\t\t\tloadAnnotInternal(child, ignoreList, synAnnot)\n",
    "\t\telif node.tag == u'ignore':\n",
    "\t\t\tterm = getTerm(node)\n",
    "\t\t\tignoreList.append(term)\n",
    "\t\telif node.tag == u'annotations':\n",
    "\t\t\tfor child in node:\n",
    "\t\t\t\tloadAnnotInternal(child, ignoreList, synAnnot)\n",
    "\n",
    "\tignoreList = []\n",
    "\tsynonyms = {}\n",
    "\ttree = etree.parse(filename)\n",
    "\troot = tree.getroot()\n",
    "\tloadAnnotInternal(root, ignoreList, synonyms)\n",
    "\treturn synonyms\n",
    "\n",
    "\n",
    "synonymDict = loadAnnotations() # TODO make a class so we don't load it EVERY time\t\n",
    "\n",
    "def getSynonym(term):\n",
    "\tif term in synonymDict:\n",
    "\t\treturn synonymDict[term]\n",
    "\t# Strip apostrophe and quotes\n",
    "\tt = re.sub(r'(\"|\\'(\\s*s)?)', u'', term)\n",
    "\tif t in synonymDict:\n",
    "\t\treturn synonymDict[t]\n",
    "\treturn term\n",
    "\n",
    "#####\n",
    "def isSafeSubstitution(term): #Don't sub if there's a chance there are multiple terms in a noun phrase\n",
    "\treturn False if re.search(r'\\b(and|or)\\b', term) or re.search(r'(,|;)', term) else True\n",
    "\n",
    "def isSimpleUsageInfoTerm(term):\n",
    "\tif not isSafeSubstitution(term):\n",
    "\t\treturn False\n",
    "\treturn True if re.search(r'^(information|data|datum|record|detail)\\s+(about|regard|of|relate\\sto)(\\s+how)?\\s+(you(r)?\\s+)?(usage|use|uses|utilzation|activity)\\s+(of|on|our)\\s+.*$', term) else False\n",
    "\n",
    "def isSimpleNonPersonalInfoTerm(term):\n",
    "\tif not isSafeSubstitution(term):\n",
    "\t\treturn False\n",
    "\tif re.search(r'^(non-(pii|personally(\\-|\\s)identif(y|iable)\\s(information|data|datum|detail)))$', term):\n",
    "\t\treturn True\n",
    "\treturn True if re.search(r'\\b((information|data|datum|detail)\\s.*\\snot\\sidentify\\s(you|user|person|individual))\\b', term) else False\n",
    "\n",
    "def isSimplePersonallyIdentifiableInfoTerm(term):\n",
    "\tif not isSafeSubstitution(term):\n",
    "\t\treturn False\n",
    "#\tif re.search(r'^((information|data|datum|detail)\\sabout\\syou)$', term):\n",
    "#\t\treturn True\n",
    "\tif re.search(r'^(pii|personally(\\-|\\s)identif(y|iable)\\s(information|data|datum|detail))$', term):\n",
    "\t\treturn True\n",
    "\treturn True if re.search(r'\\b((information|data|datum|detail)\\s.*\\sidentify\\s(you(rself)?|user|person|individual))\\b', term) else False\n",
    "\n",
    "def isSimpleIpAddr(term):\n",
    "\tif not isSafeSubstitution(term):\n",
    "\t\treturn False\n",
    "\treturn True if re.search(r'\\b((ip|internet(\\sprotocol)?)\\saddress(es)?)\\b', term) else False\n",
    "\n",
    "def simpleSynonymSub(term):\n",
    "\tif not isSafeSubstitution(term):\n",
    "\t\treturn term\n",
    "\n",
    "\tif isSimpleNonPersonalInfoTerm(term):\n",
    "\t\tterm = u'non-personally identifiable information'\n",
    "#\t\tterm = u'non-personally identifiable information'\n",
    "\telif isSimplePersonallyIdentifiableInfoTerm(term):\n",
    "\t\tterm = u'personally identifiable information'\n",
    "#\t\tterm = u'personally identifiable information'\n",
    "\telif isSimpleIpAddr(term):\n",
    "\t\tterm = u'ip address'\n",
    "\telif isSimpleUsageInfoTerm(term):\n",
    "\t\tterm = u'usage information'\n",
    "\treturn term\n",
    "\n",
    "#####\n",
    "\n",
    "def fixWhitespace(text):\n",
    "\ttext = re.sub(r'^\\s+', u'', text)\n",
    "\ttext = re.sub(r'\\s+$', u'', text)\n",
    "\treturn re.sub(r'\\s+', u' ', text)\n",
    "\n",
    "def cleanupUnicodeErrors(term):\n",
    "\t# Cleanup from mistakes before... this should really be fixed during the intial parsing of the document...\n",
    "\tt = re.sub(u'\\ufffc', u' ', term)\n",
    "\tt = re.sub(u'â€œ', u'', t)\n",
    "\tt = re.sub(u'â€\\u009d', u'', t)\n",
    "\tt = re.sub(u'â\\u0080\\u0094', u'', t)\n",
    "\tt = re.sub(u'â\\u0080\\u009d', u'', t)\n",
    "\tt = re.sub(u'â\\u0080\\u009c', u'', t)\n",
    "\tt = re.sub(u'â\\u0080\\u0099', u'', t)\n",
    "\tt = re.sub(u'â€', u'', t)\n",
    "\tt = re.sub(u'äë', u'', t)\n",
    "\tt = re.sub(u'ä', u'', t)\n",
    "\tt = re.sub(u'\\u0093', u'', t)\n",
    "\tt = re.sub(u'\\u0092', u'', t)\n",
    "\tt = re.sub(u'\\u0094', u'', t)\n",
    "\tt = re.sub(u'\\u00a7', u'', t)#Section symbol\n",
    "\tt = re.sub(u'\\u25cf', u'', t)#bullet point symbol\n",
    "\tt = re.sub(u'´', u'\\'', t)\n",
    "\tt = re.sub(u'\\u00ac', u'', t)\n",
    "\tt = re.sub(u'\\u00ad', u'-', t)\n",
    "\tt = re.sub(u'\\u2211', u'', t)\n",
    "\tt = re.sub(u'\\ufb01', u'fi', t)\n",
    "\tt = re.sub(u'\\uff0c', u', ', t)\n",
    "\tt = re.sub(u'\\uf0b7', u'', t)\n",
    "\tt = re.sub(u'\\u037e', u';', t)\n",
    "\treturn t\n",
    "\n",
    "\n",
    "def commonTermSubstitutions(term):\n",
    "\t# third-party --> third party\n",
    "\tterm = re.sub(r'\\b(third\\-party)\\b', u'third party', term)\n",
    "\tterm = re.sub(r'\\b(app(s)?|applications)\\b', u'application', term)\n",
    "\tterm = re.sub(r'\\b(wi\\-fi)\\b', u'wifi', term)\n",
    "\tterm = re.sub(r'\\b(e\\-\\s*mail)\\b', u'email', term)\n",
    "\treturn fixWhitespace(term)\n",
    "\n",
    "def stripIrrelevantTerms(term):\n",
    "\tpronRegex = re.compile(r'^(your|our|their|its|his|her|his(/|\\s(or|and)\\s)her)\\b')\n",
    "\tirrevRegex = re.compile(r'^(additional|also|available|when\\snecessary|obviously|technically|typically|basic|especially|collectively|certain|general(ly)?|follow(ing)?|important|limit(ed)?(\\s(set|amount)\\sof)?|more|most|necessary|only|optional|other|particular(ly)?|perhaps|possibl(e|y)|potential(ly)?|relate(d)?|relevant|require(d)?|select|similar|some(times)?|specific|variety\\sof|various(\\s(type|kind)(s)\\sof)?)\\b(\\s*,\\s*)?')\n",
    "\twhile pronRegex.search(term) or irrevRegex.search(term):\n",
    "\t\tterm = fixWhitespace(pronRegex.sub(u'', term))\n",
    "\t\tterm = fixWhitespace(irrevRegex.sub(u'', term))\n",
    "\treturn fixWhitespace(term)\n",
    "\n",
    "def stripEtc(term):\n",
    "\tterm = re.sub(r'\\b(etc)(\\.)?$', u'', term)\n",
    "\treturn fixWhitespace(term)\n",
    "\n",
    "def subInformation(text):\n",
    "\ttext = re.sub(r'\\b(info|datum|data)\\b', u'information', text)\n",
    "\t#this can happen when subbing data for information\n",
    "\treturn fixWhitespace(re.sub(r'\\b(information(\\s+information)+)\\b', u'information', text))\n",
    "\n",
    "\n",
    "def isFirstParty(package_name, dest_domain, privacy_policy):\n",
    "\t# Get start of packagename com.benandow.policylint --> com.benandow\n",
    "\tsplitPackageName = package_name.split(u'.')\n",
    "\trPackageName = u'{}.{}'.format(splitPackageName[0], splitPackageName[1])\n",
    "\n",
    "\t# Get root destination domain (reversed) (e.g., policylint.benandow.com --> com.benandow)\n",
    "\tsplitDestDom = dest_domain.split(u'.')\n",
    "\tif len(splitDestDom) < 2:\n",
    "\t\treturn False\n",
    "\t#rDestDomRev = u'{}.{}'.format(splitDestDom[-1], splitDestDom[-2])\n",
    "\trDestDomRev = u'{}.{}'.format(splitDestDom[0], splitDestDom[1])\n",
    "\t# Check if root dest_domain (reversed) matches start of package_name\n",
    "\tif rPackageName == rDestDomRev:\n",
    "\t\treturn True\n",
    "\t\n",
    "\tif privacy_policy is not None and type(privacy_policy) == str:\n",
    "\t\tprivacy_policy = privacy_policy#.decode(\"utf-8\")\n",
    "\n",
    "\t# Check if root privacy_policy url (reversed) matches start of package name\n",
    "\tif privacy_policy != u'NULL' and len(privacy_policy) > 0:\n",
    "\t\t#Reverse root policy URL: https://www.benandow.com/privacy --> com.benandow\n",
    "\t\tsplitDom = re.sub(r'/.*$', '', re.sub(r'http(s)?://', u'', privacy_policy)).split(u'.')\n",
    "\t\trPolUrlRev = u'{}.{}'.format(splitDom[-1], splitDom[-2])\n",
    "\t\t# Check if the root privacy policy url matches the destination domain..\n",
    "\t\tif rPolUrlRev == rDestDomRev:\n",
    "\t\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "def resolveUrl(url, packageName, policyUrl):\n",
    "\tif isFirstParty(packageName, url, policyUrl):\n",
    "\t\treturn u'we'\n",
    "\n",
    "\tif url in synonymDict:\n",
    "\t\treturn synonymDict[url]\n",
    "\treturn None\n",
    "\n",
    "def preprocess(term):\n",
    "\tdef subOrdinals(term):\n",
    "\t\tterm = re.sub(r'\\b(1st)\\b', u'first', term)\n",
    "\t\tterm = re.sub(r'\\b(3rd)\\b', u'third', term)\n",
    "\t\treturn fixWhitespace(term)\n",
    "    \n",
    "\tdef stripQuotes(term):\n",
    "\t\treturn fixWhitespace(re.sub(r'\"', u'', term))\n",
    "\n",
    "\tdef stripBeginOrEndPunct(term):\n",
    "\t\tpunctRegex = re.compile(r'((^\\s*(;|,|_|\\'|\\.|:|\\-|\\[|/)\\s*)|((;|,|_|\\.|:|\\-|\\[|/)\\s*$))')\n",
    "\t\tandOrRegex = re.compile(r'^(and|or)\\b')\n",
    "\t\twhile punctRegex.search(term) or andOrRegex.search(term):\n",
    "\t\t\tterm = fixWhitespace(punctRegex.sub(u'', term))\n",
    "\t\t\tterm = fixWhitespace(andOrRegex.sub(u'', term))\n",
    "\t\treturn term\n",
    "    \n",
    "\t##############\n",
    "\n",
    "\torigTerm = term#REMOVEME\n",
    "\tterm = cleanupUnicodeErrors(term)\n",
    "\t# Strip unbalanced parentheses\n",
    "\tif not re.search(r'\\)', term):\n",
    "\t\tterm = re.sub(r'\\(', u'', term)\n",
    "\tif not re.search(r'\\(', term):\n",
    "\t\tterm = re.sub(r'\\)', u'', term)\n",
    "\n",
    "\tterm = stripBeginOrEndPunct(term)\n",
    "\tterm = stripEtc(term)\n",
    "\tterm = stripBeginOrEndPunct(term)#Do this twice since stripping etc may result in ending with punctuation...\n",
    "\tterm = subOrdinals(term)\n",
    "\tterm = stripQuotes(term)\n",
    "\tterm = commonTermSubstitutions(term)\n",
    "\tterm = stripIrrelevantTerms(term)\n",
    "\n",
    "\tterm = fixWhitespace(term)\n",
    "\tterm = simpleSynonymSub(term)\n",
    "\tterm = subInformation(term)\n",
    "\n",
    "\tterm = getSynonym(term)\n",
    "\n",
    "\treturn term\n",
    "\n",
    "def startsWithLetter(term):\n",
    "\treturn True if re.search(r'^[a-z]', term) else False\n",
    "\n",
    "def ignorePhrases(term):\n",
    "\tif re.search(r'\\b(act(s)?|advantage|allegation|aspect|because|breach|change|condition(s)?|conduct|confidentiality|copyright|damage|destruction|disclosure|disposition|effectiveness|encryption|enforce(ment|ability)|example|exploitation|failure|freedom|functionality|handling|harm|illegal\\sconduct|impact|impossibility|improvement|integrity|lack|law|(legal|sole)\\sresponsibility|liability|limitation|loss|malfunction|misuse|(non)?infringement|privacy|policy|practice|protection|removal|right|risk(s)?|safety|sample|security|secrecy|statement|term(s)?|trademark|transfer|(unauthorized|fraudulent|illicit)\\suse|violation|warranty)\\s(of)\\b', term):\n",
    "\t\treturn True\n",
    "\tif re.search(r'\\b(privacy(\\s(policy|law(s)?|practice|statement|right|act))?|collected\\sinformation|security\\spractice|intellectual\\sproperty(\\s(right))?|information\\s(handling|gathering)|encrypt(ion)?)\\b', term):\n",
    "\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "def ignoreTerms(term):\n",
    "\treturn True if re.search(r'^\\s*(n\\.\\s*a(\\.)?|et\\sal|eula|etc|possible|us|includ(e|ing)|herein|llc|example|button|transfer|policy|factor|mean|agreement|widget|share|item|disclosure|jurisdiction|offering|way|warranty|violation|thing|implied|firewall|encryption|inc(\\.)?|thereto|trade(\\-)?\\s*mark|copyright|td|wrongdoing|hereto|hereinafter|liability)\\s*$', term) else False\n",
    "            \n",
    "def ignoreNltkStopwords(term):\n",
    "\treturn True if re.search(r'^\\s*(i|me|my|myself|we|our|ours|ourselves|you|youre|youve|youll|youd|your|yours|yourself|yourselves|he|him|his|himself|she|shes|her|hers|herself|it|its|its|itself|they|them|their|theirs|themselves|what|which|who|whom|this|that|thatll|these|those|am|is|are|was|were|be|been|being|have|has|had|having|do|does|did|doing|a|an|the|and|but|if|or|because|as|until|while|of|at|by|for|with|about|against|between|into|through|during|before|after|above|below|to|from|up|down|in|out|on|off|over|under|again|further|then|once|here|there|when|where|why|how|all|any|both|each|few|more|most|other|some|such|no|nor|not|only|own|same|so|than|too|very|s|t|can|will|just|don|dont|should|shouldve|now|d|ll|m|o|re|ve|y|ain|aren|arent|couldn|couldnt|didn|didnt|doesn|doesnt|hadn|hadnt|hasn|hasnt|haven|havent|isn|isnt|ma|mightn|mightnt|mustn|mustnt|needn|neednt|shan|shant|shouldn|shouldnt|wasn|wasnt|weren|werent|won|wont|wouldn|wouldnt)\\s*$', term) else False\n",
    "\n",
    "def ignoreWebsiteUrlLink(term):\n",
    "\treturn True if re.search(r'\\b(website_url_lnk)\\b', term) else False\n",
    "\n",
    "def isSingleLetterTerm(term):\n",
    "\treturn True if re.search(r'^\\s*[a-z]\\s*$', term) else False\n",
    "\n",
    "def startsWithOrEndsWithPrep(term):\n",
    "\treturn True if re.search(r'^\\s*(of|at|in|with|by|on|as|if|to|for)\\s', term) or re.search('\\s(of|at|in|on|with|by|as|if|to|for)\\s*$', term) else False\n",
    "\n",
    "def checkOntIgnoreList(term, negativeTermRegex, generalIgnoreRegex):\n",
    "\tif negativeTermRegex.search(term):\n",
    "\t\treturn True\n",
    "\treturn True if generalIgnoreRegex.search(term) else False\n",
    "\n",
    "def startsWithCoref(term):\n",
    "\treturn True if re.search(r'^\\s*(this|that|such)\\b', term) else False\n",
    "\n",
    "def potentialConjunction(term):\n",
    "\tif re.search(r',', term): # If it contains a comma, it could be two words together.\n",
    "\t\treturn True\n",
    "\tif re.search(r'/', term):\n",
    "\t\treturn True\n",
    "\treturn True if re.search(r'\\b(and|or)\\b', term) else False\n",
    "\n",
    "def shouldIgnoreTerm(term, generalIgnoreRegex = None, ontIgnoreRegex=None, preprocessFlag=True):\n",
    "\tif preprocessFlag:\n",
    "\t\tterm = preprocess(term)\n",
    "\tif len(term) <= 1 or potentialConjunction(term) or startsWithCoref(term) or checkOntIgnoreList(term, ontIgnoreRegex, generalIgnoreRegex) or ignoreNltkStopwords(term) or isSingleLetterTerm(term) or ignoreWebsiteUrlLink(term) or not startsWithLetter(term) or ignorePhrases(term) or ignoreTerms(term) or startsWithOrEndsWithPrep(term):\n",
    "\t\treturn True\n",
    "\treturn False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70039c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-policheckbert",
   "language": "python",
   "name": "venv-policheckbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
